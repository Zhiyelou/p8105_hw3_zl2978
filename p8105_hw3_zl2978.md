p8105\_hw3\_zl2978
================
Zhiye Lou

\#\#Problem 1  
I will first load the data.

``` r
library(p8105.datasets)
data("instacart")
```

This dataset instacart contains rows and columns. There are user / order
variables – user ID, order ID, order day, and order hour. There are also
item variables – name, aisle, department, and some numeric codes. Then I
will do some exploration of this dataset.

``` r
aisleinfo_df =
  instacart %>% 
    count(aisle) %>% 
    arrange(desc(n))
```

There are 134 aisles, and the most items ordered from is fresh
vegetables.

Then I will make a plot

``` r
instacart %>% 
    count(aisle) %>% 
    filter(n > 10000) %>% 
    mutate(
        aisle = factor(aisle),
        aisle = fct_reorder(aisle, n)
    ) %>% 
    ggplot(aes(x = aisle, y = n)) + 
    geom_point() + 
    theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```

<img src="p8105_hw3_zl2978_files/figure-gfm/unnamed-chunk-4-1.png" width="90%" />
Then I will make a table

``` r
instacart %>% 
    filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
    group_by(aisle) %>% 
    count(product_name) %>% 
    mutate(rank = min_rank(desc(n))) %>% 
    filter(rank < 4) %>% 
    arrange(aisle, rank) %>% 
    knitr::kable()
```

| aisle                      | product\_name                                 |    n | rank |
| :------------------------- | :-------------------------------------------- | ---: | ---: |
| baking ingredients         | Light Brown Sugar                             |  499 |    1 |
| baking ingredients         | Pure Baking Soda                              |  387 |    2 |
| baking ingredients         | Cane Sugar                                    |  336 |    3 |
| dog food care              | Snack Sticks Chicken & Rice Recipe Dog Treats |   30 |    1 |
| dog food care              | Organix Chicken & Brown Rice Recipe           |   28 |    2 |
| dog food care              | Small Dog Biscuits                            |   26 |    3 |
| packaged vegetables fruits | Organic Baby Spinach                          | 9784 |    1 |
| packaged vegetables fruits | Organic Raspberries                           | 5546 |    2 |
| packaged vegetables fruits | Organic Blueberries                           | 4966 |    3 |

Then I will make a table showing the mean hour of “Apples” vs “Ice
cream”

``` r
instacart %>% 
    filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
    group_by(product_name, order_dow) %>% 
    summarize(mean_hour = mean(order_hour_of_day)) %>% 
    pivot_wider(
        names_from = order_dow,
        values_from = mean_hour
    ) %>% 
  rename( 
      "Sunday" = "0",
      "Monday" = "1",
      "Tuesday" = "2",
      "Wednesday" = "3",
      "Thursday" = "4",
      "Friday" = "5",
      "Saturday" = "6") %>% 
  knitr::kable()
```

    ## `summarise()` regrouping output by 'product_name' (override with `.groups` argument)

| product\_name    |   Sunday |   Monday |  Tuesday | Wednesday | Thursday |   Friday | Saturday |
| :--------------- | -------: | -------: | -------: | --------: | -------: | -------: | -------: |
| Coffee Ice Cream | 13.77419 | 14.31579 | 15.38095 |  15.31818 | 15.21739 | 12.26316 | 13.83333 |
| Pink Lady Apples | 13.44118 | 11.36000 | 11.70213 |  14.25000 | 11.55172 | 12.78431 | 11.93750 |

\#\#Problem 2  
\#\#\#question 1  
I will first load and tidy the data.

``` r
week_nam = tibble(
  n = 0:6,
  day = c("Sunday","Monday","Tuesday","Wednesday","Thursday","Friday","Saturday"))
accel_df = 
  read_csv("./data/accel_data.csv") %>% 
  janitor::clean_names() %>%
  left_join(week_nam, by = "day") %>% 
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minutes_of_the_day",
    values_to = "activity_count") %>% 
  mutate(
    minutes_of_the_day = substr(minutes_of_the_day,10,13),
    weekday_weekend = if_else(day %in% c("Saturday","Sunday"),"Weekend","Weekday"),
    minutes_of_the_day = as.numeric(minutes_of_the_day),
    day = factor(day),
    day = fct_reorder(day,n))%>% 
  rename("day_of_the_week" = "day") %>% 
  group_by(week) %>% 
  arrange(day_of_the_week, desc(n), .by_group = TRUE) %>% 
  select(-n) %>% 
  relocate(week,day_id,day_of_the_week,weekday_weekend)
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_double(),
    ##   day = col_character()
    ## )

    ## See spec(...) for full column specifications.

There are 50400 observations in total, and there are 50400 rows and 6
columns. There are information about the time of recorded variables –
week, day\_id, day\_of\_the\_week,weekday\_weekend,
minutes\_of\_the\_day. The other important variable is the
activity\_count which is the activity counts.

\#\#\#question 2  
I will create a table and a plot showing the total activity for each
day.

``` r
acc_total_df =
   accel_df %>% 
   group_by(week,day_of_the_week,day_id) %>% 
   summarise(total_of_the_day = sum(activity_count))
```

    ## `summarise()` regrouping output by 'week', 'day_of_the_week' (override with `.groups` argument)

``` r
day_of_week_p = 
  ggplot(data = acc_total_df,aes(x = day_id,y = total_of_the_day, color = day_of_the_week)) + geom_point() + geom_line()
acc_total_df %>% 
  select(-day_id) %>% 
  knitr::kable()
```

| week | day\_of\_the\_week | total\_of\_the\_day |
| ---: | :----------------- | ------------------: |
|    1 | Sunday             |           631105.00 |
|    1 | Monday             |            78828.07 |
|    1 | Tuesday            |           307094.24 |
|    1 | Wednesday          |           340115.01 |
|    1 | Thursday           |           355923.64 |
|    1 | Friday             |           480542.62 |
|    1 | Saturday           |           376254.00 |
|    2 | Sunday             |           422018.00 |
|    2 | Monday             |           295431.00 |
|    2 | Tuesday            |           423245.00 |
|    2 | Wednesday          |           440962.00 |
|    2 | Thursday           |           474048.00 |
|    2 | Friday             |           568839.00 |
|    2 | Saturday           |           607175.00 |
|    3 | Sunday             |           467052.00 |
|    3 | Monday             |           685910.00 |
|    3 | Tuesday            |           381507.00 |
|    3 | Wednesday          |           468869.00 |
|    3 | Thursday           |           371230.00 |
|    3 | Friday             |           467420.00 |
|    3 | Saturday           |           382928.00 |
|    4 | Sunday             |           260617.00 |
|    4 | Monday             |           409450.00 |
|    4 | Tuesday            |           319568.00 |
|    4 | Wednesday          |           434460.00 |
|    4 | Thursday           |           340291.00 |
|    4 | Friday             |           154049.00 |
|    4 | Saturday           |             1440.00 |
|    5 | Sunday             |           138421.00 |
|    5 | Monday             |           389080.00 |
|    5 | Tuesday            |           367824.00 |
|    5 | Wednesday          |           445366.00 |
|    5 | Thursday           |           549658.00 |
|    5 | Friday             |           620860.00 |
|    5 | Saturday           |             1440.00 |

I will create a plot showing the mean activity for weekdays and
weekends.

``` r
weekday_vs_weekend_p = 
  accel_df %>% 
  group_by(week,weekday_weekend) %>% 
  summarise(mean_of_the_weekday_end = mean(activity_count)) %>% 
  ggplot(aes(x = week,y = mean_of_the_weekday_end, color = weekday_weekend)) + geom_point() + geom_line()
```

    ## `summarise()` regrouping output by 'week' (override with `.groups` argument)

I will create a plot showing the trend of different weeks.

``` r
week_trend_p = 
  accel_df %>% 
  group_by(week) %>% 
  summarise(total_of_week = sum(activity_count)) %>% 
ggplot(aes(x = week,y = total_of_week)) + geom_point() + geom_line()
```

    ## `summarise()` ungrouping output (override with `.groups` argument)

Then I will join three graphs together

``` r
(week_trend_p + weekday_vs_weekend_p)/day_of_week_p
```

<img src="p8105_hw3_zl2978_files/figure-gfm/unnamed-chunk-11-1.png" width="90%" />

First, the difference between weekdays and weekends are apparent. For
the first two weeks, the mean of activity counts for weekends are
greater than that of weekdays. for the rest three weeks, the mean of the
weekends has largely decreased and be smaller than the mean of weekdays.
Second, the activity counts have increased from week 1 to week 2, and
largely decreased from week 3 to week 4, and there is a smaller increase
from week 4 to week 5. Third, the difference between different days of a
week is not apparent, but Tuesday, Wednesday,and Thursday have
relatively smaller changes in activity counts among different weeks.

\#\#\#question 3 I will make a single-panel plot that shows the 24-hour
activity time courses for each day.

``` r
accel_df %>% 
  ggplot(aes(x = minutes_of_the_day, y = activity_count,color = day_of_the_week)) +    geom_line(alpha = 0.2) + stat_smooth(se = FALSE)
```

    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

<img src="p8105_hw3_zl2978_files/figure-gfm/unnamed-chunk-12-1.png" width="90%" />
Without further zoom in,the trend in different minutes of each day is
not that obvious, and thus I zoom in with the limit of activity counts
between 0 to 2000.

``` r
accel_df %>% 
  ggplot(aes(x = minutes_of_the_day, y = activity_count,color = day_of_the_week)) +  geom_line(alpha = 0.2) + stat_smooth(se = FALSE) + coord_cartesian(ylim = c(0,2000))
```

    ## `geom_smooth()` using method = 'gam' and formula 'y ~ s(x, bs = "cs")'

<img src="p8105_hw3_zl2978_files/figure-gfm/unnamed-chunk-13-1.png" width="90%" />
This plot shows that between 0 to 250 minutes (around 0:00 to 4:10), the
activity counts are pretty low. After 250 minutes, the activity counts
start to increase which implies there are more activities at day time.
Then, around 1250 minutes (around 20:50), the activity counts start to
decrease and this implies there are less activities at evening and night
time. Finally, the activity counts get close to 0 around 1440 minutes
(around 24:00), and this suggests there is almost no activity at
mid-night.

\#\#Problem 3 I will frist load the data.

``` r
library(p8105.datasets)
data("ny_noaa")
```

For this data set, there are 2595176 rows and 7 columns. This datasets
has the weather station id – id. There is also a variable date, and
weather variables – prcp (precipitation), snow, snwd (snow depth),
tmax(maximum temperature), and tmin(minimum temperature). There is 0 row
that does not have missing value, and the reason for these missing
values is unknown, and thus these missing value could be problematic.
